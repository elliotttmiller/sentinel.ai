[32m2025-07-31 14:05:32.559[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36m_initialize_wandb[0m:[36m107[0m - [1m‚úÖ Weights & Biases initialized successfully[0m
2025-07-31 14:05:32,563 - SystemOptimizationHub - INFO - [INFO] Weave observability initialized for system optimization hub
üß™ Running comprehensive test suite...
üöÄ WEAVE-ENHANCED SYSTEM OPTIMIZATION HUB - Starting Comprehensive Test Suite
================================================================================
üîç Full observability and monitoring enabled
================================================================================
2025-07-31 14:05:32,568 - SystemOptimizationHub - INFO - [START] STARTING TEST: System Initialization (system_initialization)
[32m2025-07-31 14:05:32.607[0m | [32m[1mSUCCESS [0m | [36msrc.utils.sentry_integration[0m:[36m_initialize_sentry[0m:[36m78[0m - [32m[1mSentry integration initialized successfully[0m
[32m2025-07-31 14:05:32.609[0m | [32m[1mSUCCESS [0m | [36msrc.utils.google_ai_wrapper[0m:[36m__init__[0m:[36m68[0m - [32m[1mGoogle Generative AI wrapper initialized successfully with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:32.610[0m | [1mINFO    [0m | [36msrc.core.cognitive_forge_engine[0m:[36m__init__[0m:[36m69[0m - [1mGoogle Generative AI initialized with model: gemini-1.5-pro[0m
2025-07-31 14:05:32,617 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o4509683080822784.ingest.us.sentry.io:443
2025-07-31 14:05:32,618 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:32.618[0m | [1mINFO    [0m | [36msrc.utils.phoenix_protocol[0m:[36m__init__[0m:[36m23[0m - [1mPhoenix Protocol initialized - Self-healing system active[0m
2025-07-31 14:05:32,621 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:32,624 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:32.625[0m | [1mINFO    [0m | [36msrc.utils.guardian_protocol[0m:[36m__init__[0m:[36m33[0m - [1mGuardian Protocol initialized - Quality assurance system active[0m
[32m2025-07-31 14:05:32.625[0m | [1mINFO    [0m | [36msrc.utils.synapse_logging[0m:[36m__init__[0m:[36m33[0m - [1mSynapse Logging System initialized - Unified consciousness active[0m
2025-07-31 14:05:32,629 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:32,631 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:32.633[0m | [1mINFO    [0m | [36msrc.utils.self_learning_module[0m:[36m__init__[0m:[36m25[0m - [1mSelf-Learning Module initialized - Continuous improvement active[0m
[32m2025-07-31 14:05:32.633[0m | [1mINFO    [0m | [36msrc.core.cognitive_forge_engine[0m:[36m__init__[0m:[36m109[0m - [1mCognitive Forge Engine v5.0 initialized with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:32.634[0m | [1mINFO    [0m | [36msrc.core.cognitive_forge_engine[0m:[36m__init__[0m:[36m110[0m - [1mSentient Operating System: Phoenix Protocol, Guardian Protocol, and Synapse Logging active[0m
2025-07-31 14:05:32,644 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: System Initialization - PASS
[32m2025-07-31 14:05:32.646[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'System Initialization', 'category': 'system_initialization', 'execution_time': 0.07296872138977051, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 23.5, 'cpu_end': 34.6, 'cpu_usage': 29.05}}[0m
2025-07-31 14:05:32,652 - SystemOptimizationHub - INFO - [START] STARTING TEST: Environment Validation (environment_validation)
2025-07-31 14:05:32,657 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Environment Validation - PASS
[32m2025-07-31 14:05:32.658[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Environment Validation', 'category': 'environment_validation', 'execution_time': 0.0061190128326416016, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 50.0, 'cpu_end': 0.0, 'cpu_usage': 25.0}}[0m
2025-07-31 14:05:32,667 - SystemOptimizationHub - INFO - [START] STARTING TEST: Database Connectivity (database_integration)
[32m2025-07-31 14:05:32.908[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: test_db_1753988732[0m
2025-07-31 14:05:33,077 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Database Connectivity - PASS
[32m2025-07-31 14:05:33.078[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Database Connectivity', 'category': 'database_integration', 'execution_time': 0.41236066818237305, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 100.0, 'cpu_end': 14.9, 'cpu_usage': 57.45}}[0m
2025-07-31 14:05:33,080 - SystemOptimizationHub - INFO - [START] STARTING TEST: Agent Factory (agent_factory)
2025-07-31 14:05:33,085 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,090 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,092 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,095 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,097 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,100 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,103 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,105 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,108 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,111 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,113 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,120 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Agent Factory - PASS
[32m2025-07-31 14:05:33.121[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Agent Factory', 'category': 'agent_factory', 'execution_time': 0.035039663314819336, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 43.2, 'cpu_usage': 21.6}}[0m
2025-07-31 14:05:33,127 - SystemOptimizationHub - INFO - [START] STARTING TEST: Protocol Systems (protocol_systems)
2025-07-31 14:05:33,133 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Protocol Systems - PASS
[32m2025-07-31 14:05:33.134[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Protocol Systems', 'category': 'protocol_systems', 'execution_time': 0.005253314971923828, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 8.3, 'cpu_end': 0.0, 'cpu_usage': 4.15}}[0m
2025-07-31 14:05:33,142 - SystemOptimizationHub - INFO - [START] STARTING TEST: Workflow Phases (workflow_phases)
2025-07-31 14:05:33,145 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,155 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[36m‚ï≠‚îÄ[0m[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[36m Crew Execution Started [0m[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[36m‚îÄ‚ïÆ[0m
[36m‚îÇ[0m                                                                                                [36m‚îÇ[0m
[36m‚îÇ[0m  [1;36mCrew Execution Started[0m                                                                        [36m‚îÇ[0m
[36m‚îÇ[0m  [37mName: [0m[36mcrew[0m                                                                                    [36m‚îÇ[0m
[36m‚îÇ[0m  [37mID: [0m[36mda375292-0a07-47f9-8c49-b9134a51299e[0m                                                      [36m‚îÇ[0m
[36m‚îÇ[0m  [37mTool Args: [0m                                                                                   [36m‚îÇ[0m
[36m‚îÇ[0m                                                                                                [36m‚îÇ[0m
[36m‚îÇ[0m                                                                                                [36m‚îÇ[0m
[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

2025-07-31 14:05:33,173 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
2025-07-31 14:05:33,178 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[?25l2025-07-31 14:05:33,182 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[1;36müöÄ Crew: [0m[1;36mcrew[0m
‚îî‚îÄ‚îÄ [1;33müìã Task: a456c6ef-bd62-4801-be7c-41c8c28779c3[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
[?25h[35m‚ï≠‚îÄ[0m[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[35m ü§ñ Agent Started [0m[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[35m‚îÄ‚ïÆ[0m
[35m‚îÇ[0m                                                                                                [35m‚îÇ[0m
[35m‚îÇ[0m  [37mAgent: [0m[1;92mAdvanced Prompt Optimization Specialist[0m                                                [35m‚îÇ[0m
[35m‚îÇ[0m                                                                                                [35m‚îÇ[0m
[35m‚îÇ[0m  [37mTask: [0m[92mAnalyze and optimize the following user prompt: 'Create a simple Python web [0m            [35m‚îÇ[0m
[35m‚îÇ[0m  [92mapplication with FastAPI'.[0m                                                                    [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                [0m                                                                              [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                Your transformation process must include:[0m                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                1. **Ambiguity Resolution**: Clarify any vague terms[0m                          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                2. **Contextual Enrichment**: Add implicit technical constraints or context[0m   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                3. **Define Success Criteria**: Create a list of measurable outcomes[0m          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the[0m  [35m‚îÇ[0m
[35m‚îÇ[0m  [92mtask[0m                                                                                          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                5. **Structure the Output**: Return a single, raw JSON object containing the[0m  [35m‚îÇ[0m
[35m‚îÇ[0m  [92m'optimized_prompt', 'success_criteria', and 'recommended_agents'[0m                              [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                [0m                                                                              [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                Provide your response in the following JSON format:[0m                           [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                {[0m                                                                             [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "optimized_prompt": "The enhanced, detailed version of the user's [0m        [35m‚îÇ[0m
[35m‚îÇ[0m  [92mrequest",[0m                                                                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "technical_context": {[0m                                                    [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "programming_languages": ["list", "of", "relevant", "languages"],[0m     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "frameworks": ["list", "of", "relevant", "frameworks"],[0m               [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "tools_required": ["list", "of", "required", "tools"],[0m                [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "complexity_level": "low/medium/high",[0m                                [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "estimated_duration": "time estimate"[0m                                 [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    },[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "success_criteria": [[0m                                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "Specific, measurable criteria 1",[0m                                    [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "Specific, measurable criteria 2"[0m                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ],[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "recommended_agents": [[0m                                                   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "agent_role_1",[0m                                                       [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "agent_role_2"[0m                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ],[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "risk_factors": [[0m                                                         [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "potential risk 1 with mitigation",[0m                                   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "potential risk 2 with mitigation"[0m                                    [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ],[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "optimization_notes": [[0m                                                   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "optimization suggestion 1",[0m                                          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "optimization suggestion 2"[0m                                           [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ][0m                                                                         [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                }[0m                                                                             [35m‚îÇ[0m
[35m‚îÇ[0m                                                                                                [35m‚îÇ[0m
[35m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

[?25l2025-07-31 14:05:33,193 - LiteLLM - DEBUG -

2025-07-31 14:05:33,194 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
2025-07-31 14:05:33,195 - LiteLLM - DEBUG - [92mlitellm.completion(model='gemini-1.5-pro', messages=[{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'Create a simple Python web application with FastAPI\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], temperature=0.7, stop=['\nObserv
2025-07-31 14:05:33,195 - LiteLLM - DEBUG -

2025-07-31 14:05:33,196 - LiteLLM - DEBUG - Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>]
2025-07-31 14:05:33,197 - LiteLLM - DEBUG - self.optional_params: {}
2025-07-31 14:05:33,199 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-31 14:05:33,211 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,214 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-pro; provider = vertex_ai
2025-07-31 14:05:33,215 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-pro', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'vertex_ai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'Create a simple Python web application with FastAPI\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "p
2025-07-31 14:05:33,216 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:33,216 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}
2025-07-31 14:05:33,217 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:33,218 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,221 - LiteLLM - DEBUG - Checking cached credentials for project_id: None
2025-07-31 14:05:33,221 - LiteLLM - DEBUG - Credential cache key not found for project_id: None, loading new credentials
2025-07-31 14:05:33,224 - google.auth._default - DEBUG - Checking D:\AMD\secrets\nexus-ai-466614-377f29052243.json for explicit credentials as part of auth process...
2025-07-31 14:05:33,274 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
2025-07-31 14:05:33,288 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oauth2.googleapis.com:443
[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:33,845 - urllib3.connectionpool - DEBUG - https://oauth2.googleapis.com:443 "POST /token HTTP/1.1" 200 None
2025-07-31 14:05:33,849 - LiteLLM - DEBUG - Validating credentials for project_id: None
2025-07-31 14:05:33,850 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,852 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,855 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent \
-H 'Content-Type: application/json' -H 'Authorization: Be****t8' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Analyze and optimize the following user prompt: \'Create a simple Python web application with FastAPI\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}], 'system_instruction': {'parts': [{'text': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}]}, 'generationConfig': {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}}'
[0m

[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:34,226 - httpcore.connection - DEBUG - connect_tcp.started host='us-central1-aiplatform.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-31 14:05:34,328 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C71A5A50>
2025-07-31 14:05:34,328 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C7C71ED130> server_hostname='us-central1-aiplatform.googleapis.com' timeout=600.0
2025-07-31 14:05:34,368 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C71A6490>
2025-07-31 14:05:34,371 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-31 14:05:34,371 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-31 14:05:34,371 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-31 14:05:34,372 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-31 14:05:34,373 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:34,519 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 31 Jul 2025 19:05:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-31 14:05:34,520 - httpx - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent "HTTP/1.1 404 Not Found"
2025-07-31 14:05:34,521 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-31 14:05:34,522 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-31 14:05:34,523 - httpcore.http11 - DEBUG - response_closed.started
2025-07-31 14:05:34,523 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-31 14:05:34,525 - LiteLLM - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-07-31 14:05:34,535 - LiteLLM - DEBUG - Logging Details LiteLLM-Failure Call: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>]
[2K[1;36müöÄ Crew: [0m[1;36mcrew[0m                    ...                                                [0m
‚îî‚îÄ‚îÄ [1;33müìã Task: a456c6ef-bd62-4801-be7c-41c8c28779c3[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
    ‚îî‚îÄ‚îÄ [1;31m‚ùå LLM Failed[0m
[?25h[31m‚ï≠‚îÄ[0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m LLM Error [0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [1;31m‚ùå LLM Call Failed[0m                                                                            [31m‚îÇ[0m
[31m‚îÇ[0m  [37mError: [0m[31mlitellm.NotFoundError: VertexAIException - {[0m                                           [31m‚îÇ[0m
[31m‚îÇ[0m  [31m  "error": {[0m                                                                                  [31m‚îÇ[0m
[31m‚îÇ[0m  [31m    "code": 404,[0m                                                                              [31m‚îÇ[0m
[31m‚îÇ[0m  [31m    "message": "Publisher Model [0m                                                              [31m‚îÇ[0m
[31m‚îÇ[0m  [31m`projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was[0m  [31m‚îÇ[0m
[31m‚îÇ[0m  [31mnot found or your project does not have access to it. Please ensure you are using a valid [0m    [31m‚îÇ[0m
[31m‚îÇ[0m  [31mmodel version. For more information, see: [0m                                                    [31m‚îÇ[0m
[31m‚îÇ[0m  [31mhttps://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",[0m                  [31m‚îÇ[0m
[31m‚îÇ[0m  [31m    "status": "NOT_FOUND"[0m                                                                     [31m‚îÇ[0m
[31m‚îÇ[0m  [31m  }[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m  [31m}[0m                                                                                             [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

[?25l[1;36müöÄ Crew: [0m[1;36mcrew[0m
‚îî‚îÄ‚îÄ [1;31müìã Task: a456c6ef-bd62-4801-be7c-41c8c28779c3[0m
    [37mAssigned to: [0m[31mAdvanced Prompt Optimization Specialist[0m
    [37mStatus: [0m[1;31m‚ùå Failed[0m
    ‚îî‚îÄ‚îÄ [1;31m‚ùå LLM Failed[0m
[?25h[31m‚ï≠‚îÄ[0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m Task Failure [0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [1;31mTask Failed[0m                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m  [37mName: [0m[31ma456c6ef-bd62-4801-be7c-41c8c28779c3[0m                                                    [31m‚îÇ[0m
[31m‚îÇ[0m  [37mAgent: [0m[31mAdvanced Prompt Optimization Specialist[0m                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [37mTool Args: [0m                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

[31m‚ï≠‚îÄ[0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m Crew Failure [0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [1;31mCrew Execution Failed[0m                                                                         [31m‚îÇ[0m
[31m‚îÇ[0m  [37mName: [0m[31mcrew[0m                                                                                    [31m‚îÇ[0m
[31m‚îÇ[0m  [37mID: [0m[31mda375292-0a07-47f9-8c49-b9134a51299e[0m                                                      [31m‚îÇ[0m
[31m‚îÇ[0m  [37mTool Args: [0m                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m  [37mFinal Output: [0m                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
[32m2025-07-31 14:05:34.558[0m | [31m[1mERROR   [0m | [36msrc.core.cognitive_forge_engine[0m:[36m_execute_prompt_alchemy[0m:[36m349[0m - [31m[1mPrompt optimization failed: litellm.NotFoundError: VertexAIException - {
  "error": {
    "code": 404,
    "message": "Publisher Model `projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
    "status": "NOT_FOUND"
  }
}
[0m

2025-07-31 14:05:34,576 - SystemOptimizationHub - INFO - [FAIL] TEST COMPLETED: Workflow Phases - FAIL
[32m2025-07-31 14:05:34.578[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_failure - {'test_name': 'Workflow Phases', 'category': 'workflow_phases', 'execution_time': 1.4334053993225098, 'error': "unsupported operand type(s) for +: 'int' and 'str'", 'performance_metrics': {'memory_start': 52.8, 'memory_end': 53.0, 'memory_delta': 0.20000000000000284, 'cpu_start': 43.8, 'cpu_end': 18.7, 'cpu_usage': 31.25}}[0m
2025-07-31 14:05:34,581 - SystemOptimizationHub - INFO - [START] STARTING TEST: Performance Optimization (performance_optimization)
üöÄ Testing System Performance & Optimization...
   üìä This test evaluates your system's resource usage and performance capabilities
   üéØ Each metric is graded from A+ (Excellent) to F (Critical)

   üß† MEMORY USAGE ANALYSIS
      üìä Usage: 52.9% (8.4GB / 15.9GB)
      üìä Available: 7.5GB
      üéØ Grade: A
      üí° GOOD: Your system has adequate memory for most operations. Performance should be smooth.
      üîß Recommendation: Memory usage is healthy. Monitor during heavy workloads.

   ‚ö° CPU USAGE ANALYSIS
2025-07-31 14:05:34,641 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
2025-07-31 14:05:35,196 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): telemetry.crewai.com:4319
      üìä Usage: 9.5%
      üìä Cores: 16
      üìä Frequency: 3700MHz
      üéØ Grade: A+
      üí° EXCELLENT: CPU usage is very low. Your system has plenty of processing power available.
      üîß Recommendation: CPU performance is optimal. No action needed.

   üíæ DISK USAGE ANALYSIS
      üìä Usage: 56.9% (200.1GB free / 464.4GB total)
      üéØ Grade: A+
      üí° EXCELLENT: Plenty of disk space available. No storage concerns.
      üîß Recommendation: Disk space is optimal. No action needed.

   üìà SYSTEM LOAD ANALYSIS
      üìä 1min: 0.00, 5min: 0.00, 15min: 0.00
      üéØ Grade: A+
      üí° EXCELLENT: System load is very low. Plenty of processing capacity available.

   üéØ OVERALL PERFORMANCE ASSESSMENT
      üéØ Overall Grade: A+ (94/100)
      üìä Status: EXCELLENT
      üí° Your system is performing exceptionally well! All resources are optimally utilized.
      üîß Your system is ready for intensive AI operations. No optimizations needed.

2025-07-31 14:05:35,951 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Performance Optimization - PASS
[32m2025-07-31 14:05:35.952[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Performance Optimization', 'category': 'performance_optimization', 'execution_time': 1.3671648502349854, 'performance_metrics': {'memory_start': 53.0, 'memory_end': 52.8, 'memory_delta': -0.20000000000000284, 'cpu_start': 0.0, 'cpu_end': 19.6, 'cpu_usage': 9.8}}[0m
2025-07-31 14:05:35,959 - SystemOptimizationHub - INFO - [START] STARTING TEST: Error Handling (error_handling)
üîç Testing Error Handling Capabilities...
   üìù Note: These tests INTENTIONALLY trigger errors to verify proper handling
   ‚úÖ A 'PASS' means the system correctly detected and handled the error
   ‚ùå A 'FAIL' means the system failed to handle the error properly

   üß™ Test 1: Empty Prompt Detection
2025-07-31 14:05:35,963 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:35,968 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[36m‚ï≠‚îÄ[0m[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[36m Crew Execution Started [0m[36m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[36m‚îÄ‚ïÆ[0m
[36m‚îÇ[0m                                                                                                [36m‚îÇ[0m
[36m‚îÇ[0m  [1;36mCrew Execution Started[0m                                                                        [36m‚îÇ[0m
[36m‚îÇ[0m  [37mName: [0m[36mcrew[0m                                                                                    [36m‚îÇ[0m
[36m‚îÇ[0m  [37mID: [0m[36me79e3957-18b0-4ca5-93c8-c612b1f5525b[0m                                                      [36m‚îÇ[0m
[36m‚îÇ[0m  [37mTool Args: [0m                                                                                   [36m‚îÇ[0m
[36m‚îÇ[0m                                                                                                [36m‚îÇ[0m
[36m‚îÇ[0m                                                                                                [36m‚îÇ[0m
[36m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

2025-07-31 14:05:35,986 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[?25l2025-07-31 14:05:35,990 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[1;36müöÄ Crew: [0m[1;36mcrew[0m
‚îî‚îÄ‚îÄ [1;33müìã Task: fc54f199-8112-4622-8c1f-cbea00fc02d6[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
[?25h[35m‚ï≠‚îÄ[0m[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[35m ü§ñ Agent Started [0m[35m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[35m‚îÄ‚ïÆ[0m
[35m‚îÇ[0m                                                                                                [35m‚îÇ[0m
[35m‚îÇ[0m  [37mAgent: [0m[1;92mAdvanced Prompt Optimization Specialist[0m                                                [35m‚îÇ[0m
[35m‚îÇ[0m                                                                                                [35m‚îÇ[0m
[35m‚îÇ[0m  [37mTask: [0m[92mAnalyze and optimize the following user prompt: ''.[0m                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                [0m                                                                              [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                Your transformation process must include:[0m                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                1. **Ambiguity Resolution**: Clarify any vague terms[0m                          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                2. **Contextual Enrichment**: Add implicit technical constraints or context[0m   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                3. **Define Success Criteria**: Create a list of measurable outcomes[0m          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the[0m  [35m‚îÇ[0m
[35m‚îÇ[0m  [92mtask[0m                                                                                          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                5. **Structure the Output**: Return a single, raw JSON object containing the[0m  [35m‚îÇ[0m
[35m‚îÇ[0m  [92m'optimized_prompt', 'success_criteria', and 'recommended_agents'[0m                              [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                [0m                                                                              [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                Provide your response in the following JSON format:[0m                           [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                {[0m                                                                             [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "optimized_prompt": "The enhanced, detailed version of the user's [0m        [35m‚îÇ[0m
[35m‚îÇ[0m  [92mrequest",[0m                                                                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "technical_context": {[0m                                                    [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "programming_languages": ["list", "of", "relevant", "languages"],[0m     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "frameworks": ["list", "of", "relevant", "frameworks"],[0m               [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "tools_required": ["list", "of", "required", "tools"],[0m                [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "complexity_level": "low/medium/high",[0m                                [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "estimated_duration": "time estimate"[0m                                 [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    },[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "success_criteria": [[0m                                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "Specific, measurable criteria 1",[0m                                    [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "Specific, measurable criteria 2"[0m                                     [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ],[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "recommended_agents": [[0m                                                   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "agent_role_1",[0m                                                       [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "agent_role_2"[0m                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ],[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "risk_factors": [[0m                                                         [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "potential risk 1 with mitigation",[0m                                   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "potential risk 2 with mitigation"[0m                                    [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ],[0m                                                                        [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    "optimization_notes": [[0m                                                   [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "optimization suggestion 1",[0m                                          [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                        "optimization suggestion 2"[0m                                           [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                    ][0m                                                                         [35m‚îÇ[0m
[35m‚îÇ[0m  [92m                }[0m                                                                             [35m‚îÇ[0m
[35m‚îÇ[0m                                                                                                [35m‚îÇ[0m
[35m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

[?25l2025-07-31 14:05:35,999 - LiteLLM - DEBUG -

2025-07-31 14:05:36,000 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
2025-07-31 14:05:36,000 - LiteLLM - DEBUG - [92mlitellm.completion(model='gemini-1.5-pro', messages=[{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], temperature=0.7, stop=['\nObservation:'], stream=False)[0m
2025-07-31 14:05:36,001 - LiteLLM - DEBUG -

2025-07-31 14:05:36,001 - LiteLLM - DEBUG - Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>], not adding again..
2025-07-31 14:05:36,002 - LiteLLM - DEBUG - Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>], not adding again..
2025-07-31 14:05:36,003 - LiteLLM - DEBUG - Initialized litellm callbacks, Async Success Callbacks: ['cache', <crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C7332250>]
2025-07-31 14:05:36,006 - LiteLLM - DEBUG - self.optional_params: {}
2025-07-31 14:05:36,007 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-31 14:05:36,009 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,010 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-pro; provider = vertex_ai
2025-07-31 14:05:36,011 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-pro', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'vertex_ai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n
2025-07-31 14:05:36,013 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:36,015 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}
2025-07-31 14:05:36,016 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:36,017 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,020 - LiteLLM - DEBUG - Checking cached credentials for project_id: None
2025-07-31 14:05:36,022 - LiteLLM - DEBUG - Cached credentials found for project_id: None.
2025-07-31 14:05:36,022 - LiteLLM - DEBUG - Using cached credentials
2025-07-31 14:05:36,025 - LiteLLM - DEBUG - Validating credentials for project_id: None
2025-07-31 14:05:36,026 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,027 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,028 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent \
-H 'Content-Type: application/json' -H 'Authorization: Be****t8' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Analyze and optimize the following user prompt: \'\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}], 'system_instruction': {'parts': [{'text': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}]}, 'generationConfig': {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}}'
[0m

2025-07-31 14:05:36,060 - urllib3.connectionpool - DEBUG - https://telemetry.crewai.com:4319 "POST /v1/traces HTTP/1.1" 200 2
[1;31m                                               ...                                                [0m2025-07-31 14:05:36,421 - httpcore.connection - DEBUG - connect_tcp.started host='us-central1-aiplatform.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-31 14:05:36,459 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C7618F10>
2025-07-31 14:05:36,460 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C7C76085F0> server_hostname='us-central1-aiplatform.googleapis.com' timeout=600.0
2025-07-31 14:05:36,493 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C7618ED0>
2025-07-31 14:05:36,494 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:36,657 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 31 Jul 2025 19:05:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-31 14:05:36,661 - httpx - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent "HTTP/1.1 404 Not Found"
2025-07-31 14:05:36,663 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-31 14:05:36,664 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-31 14:05:36,665 - httpcore.http11 - DEBUG - response_closed.started
2025-07-31 14:05:36,666 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-31 14:05:36,667 - LiteLLM - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-07-31 14:05:36,674 - LiteLLM - DEBUG - Logging Details LiteLLM-Failure Call: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>]
[2K[1;36müöÄ Crew: [0m[1;36mcrew[0m                    ...                                                [0m
‚îî‚îÄ‚îÄ [1;33müìã Task: fc54f199-8112-4622-8c1f-cbea00fc02d6[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
    ‚îî‚îÄ‚îÄ [1;31m‚ùå LLM Failed[0m
[?25h[31m‚ï≠‚îÄ[0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m LLM Error [0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [1;31m‚ùå LLM Call Failed[0m                                                                            [31m‚îÇ[0m
[31m‚îÇ[0m  [37mError: [0m[31mlitellm.NotFoundError: VertexAIException - {[0m                                           [31m‚îÇ[0m
[31m‚îÇ[0m  [31m  "error": {[0m                                                                                  [31m‚îÇ[0m
[31m‚îÇ[0m  [31m    "code": 404,[0m                                                                              [31m‚îÇ[0m
[31m‚îÇ[0m  [31m    "message": "Publisher Model [0m                                                              [31m‚îÇ[0m
[31m‚îÇ[0m  [31m`projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was[0m  [31m‚îÇ[0m
[31m‚îÇ[0m  [31mnot found or your project does not have access to it. Please ensure you are using a valid [0m    [31m‚îÇ[0m
[31m‚îÇ[0m  [31mmodel version. For more information, see: [0m                                                    [31m‚îÇ[0m
[31m‚îÇ[0m  [31mhttps://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",[0m                  [31m‚îÇ[0m
[31m‚îÇ[0m  [31m    "status": "NOT_FOUND"[0m                                                                     [31m‚îÇ[0m
[31m‚îÇ[0m  [31m  }[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m  [31m}[0m                                                                                             [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

[?25l[1;36müöÄ Crew: [0m[1;36mcrew[0m
‚îî‚îÄ‚îÄ [1;31müìã Task: fc54f199-8112-4622-8c1f-cbea00fc02d6[0m
    [37mAssigned to: [0m[31mAdvanced Prompt Optimization Specialist[0m
    [37mStatus: [0m[1;31m‚ùå Failed[0m
    ‚îî‚îÄ‚îÄ [1;31m‚ùå LLM Failed[0m
[?25h[31m‚ï≠‚îÄ[0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m Task Failure [0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [1;31mTask Failed[0m                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m  [37mName: [0m[31mfc54f199-8112-4622-8c1f-cbea00fc02d6[0m                                                    [31m‚îÇ[0m
[31m‚îÇ[0m  [37mAgent: [0m[31mAdvanced Prompt Optimization Specialist[0m                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [37mTool Args: [0m                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m

[31m‚ï≠‚îÄ[0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m Crew Failure [0m[31m‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[0m[31m‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m  [1;31mCrew Execution Failed[0m                                                                         [31m‚îÇ[0m
[31m‚îÇ[0m  [37mName: [0m[31mcrew[0m                                                                                    [31m‚îÇ[0m
[31m‚îÇ[0m  [37mID: [0m[31me79e3957-18b0-4ca5-93c8-c612b1f5525b[0m                                                      [31m‚îÇ[0m
[31m‚îÇ[0m  [37mTool Args: [0m                                                                                   [31m‚îÇ[0m
[31m‚îÇ[0m  [37mFinal Output: [0m                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                                [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
[32m2025-07-31 14:05:36.692[0m | [31m[1mERROR   [0m | [36msrc.core.cognitive_forge_engine[0m:[36m_execute_prompt_alchemy[0m:[36m349[0m - [31m[1mPrompt optimization failed: litellm.NotFoundError: VertexAIException - {
  "error": {
    "code": 404,
    "message": "Publisher Model `projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
    "status": "NOT_FOUND"
  }
}
[0m

      ‚úÖ Expected error caught: NotFoundError
   üß™ Test 2: Database Error Handling
2025-07-31 14:05:36,781 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
      ‚úÖ Database gracefully returned None for invalid mission ID
   üß™ Test 3: Agent Creation Error Handling

üìä Error Handling Test Summary:
   ‚úÖ empty_prompt_handling: PASSED - System correctly detected empty prompt
   ‚úÖ database_error_handling: PASSED - Database returned None for invalid ID
   ‚ùå agent_creation_error_handling: FAILED - Agent creation should have failed

üí° Understanding Error Handling Tests:
   ‚Ä¢ These tests INTENTIONALLY trigger error conditions
   ‚Ä¢ A 'PASS' means the system correctly detected and handled the error
   ‚Ä¢ A 'FAIL' means the system failed to handle the error properly
   ‚Ä¢ The goal is to ensure the system is robust and doesn't crash

üìä PERFORMANCE GRADING SCALE:
   üèÜ A+ (95-100): EXCELLENT - Optimal performance, ready for intensive operations
   ü•á A  (90-94): GOOD - Strong performance with minor optimization opportunities
   ü•à B  (80-89): ACCEPTABLE - Adequate performance, some areas for improvement
   ü•â C  (70-79): CONCERNING - Performance issues that should be addressed
   ‚ö†Ô∏è  D  (60-69): PROBLEMATIC - Significant performance problems
   üö® F  (50-59): CRITICAL - Severe performance issues requiring immediate attention

üéØ WHY PERFORMANCE MATTERS FOR AI:
   ‚Ä¢ Memory: AI operations require significant RAM for processing large datasets
   ‚Ä¢ CPU: Complex AI calculations need processing power for timely results
   ‚Ä¢ Disk: AI models and data storage require adequate space
   ‚Ä¢ Load: System responsiveness affects AI operation efficiency
2025-07-31 14:05:36,841 - SystemOptimizationHub - INFO - [FAIL] TEST COMPLETED: Error Handling - FAIL
[32m2025-07-31 14:05:36.841[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_failure - {'test_name': 'Error Handling', 'category': 'error_handling', 'execution_time': 0.8813502788543701, 'error': 'Unknown error', 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.9, 'memory_delta': 0.10000000000000142, 'cpu_start': 0.0, 'cpu_end': 22.1, 'cpu_usage': 11.05}}[0m
2025-07-31 14:05:36,848 - SystemOptimizationHub - INFO - [START] STARTING TEST: Integration Tests (integration_tests)
2025-07-31 14:05:36,854 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Integration Tests - PASS
[32m2025-07-31 14:05:36.855[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Integration Tests', 'category': 'integration_tests', 'execution_time': 0.0066988468170166016, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.9, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 100.0, 'cpu_usage': 50.0}}[0m
2025-07-31 14:05:36,862 - SystemOptimizationHub - INFO - [START] STARTING TEST: Fix-AI Integration (fix_ai_integration)
2025-07-31 14:05:36,863 - SystemOptimizationHub - INFO - [START] STARTING TEST: Fix-AI Integration (fix_ai_integration)
[32m2025-07-31 14:05:36.870[0m | [32m[1mSUCCESS [0m | [36msrc.utils.google_ai_wrapper[0m:[36m__init__[0m:[36m68[0m - [32m[1mGoogle Generative AI wrapper initialized successfully with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:36.873[0m | [1mINFO    [0m | [36msrc.utils.crewai_bypass[0m:[36mconfigure_direct_ai_environment[0m:[36m108[0m - [1mDirect AI environment configured - LiteLLM disabled[0m
2025-07-31 14:05:36,875 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Fix-AI Integration - PASS
2025-07-31 14:05:36,882 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Fix-AI Integration - PASS
[32m2025-07-31 14:05:36.883[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Fix-AI Integration', 'category': 'fix_ai_integration', 'execution_time': 0.01949286460876465, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.9, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 18.8, 'cpu_usage': 9.4}}[0m
2025-07-31 14:05:36,889 - SystemOptimizationHub - INFO - [START] STARTING TEST: Automated Debugging System (automated_debugging)
2025-07-31 14:05:36,890 - SystemOptimizationHub - INFO - [START] STARTING TEST: Automated Debugging System (automated_debugging)
[32m2025-07-31 14:05:36.891[0m | [1mINFO    [0m | [36msrc.utils.automated_debugger[0m:[36m__init__[0m:[36m36[0m - [1mAutomated Debugger initialized[0m
[32m2025-07-31 14:05:36.892[0m | [1mINFO    [0m | [36msrc.utils.crewai_bypass[0m:[36mconfigure_direct_ai_environment[0m:[36m108[0m - [1mDirect AI environment configured - LiteLLM disabled[0m
2025-07-31 14:05:36,893 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Automated Debugging System - PASS
2025-07-31 14:05:36,898 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Automated Debugging System - PASS
[32m2025-07-31 14:05:36.899[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Automated Debugging System', 'category': 'automated_debugging', 'execution_time': 0.009461641311645508, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.9, 'memory_delta': 0.0, 'cpu_start': 46.7, 'cpu_end': 0.0, 'cpu_usage': 23.35}}[0m
2025-07-31 14:05:36,906 - SystemOptimizationHub - INFO - [START] STARTING TEST: Sentry Integration (sentry_integration)
2025-07-31 14:05:36,907 - SystemOptimizationHub - INFO - [START] STARTING TEST: Sentry Integration (sentry_integration)
[32m2025-07-31 14:05:36.948[0m | [32m[1mSUCCESS [0m | [36msrc.utils.sentry_integration[0m:[36m_initialize_sentry[0m:[36m78[0m - [32m[1mSentry integration initialized successfully[0m
2025-07-31 14:05:36,949 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Sentry Integration - PASS
2025-07-31 14:05:36,955 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Sentry Integration - PASS
[32m2025-07-31 14:05:36.956[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Sentry Integration', 'category': 'sentry_integration', 'execution_time': 0.04905509948730469, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.8, 'memory_delta': -0.10000000000000142, 'cpu_start': 100.0, 'cpu_end': 29.2, 'cpu_usage': 64.6}}[0m
2025-07-31 14:05:36,963 - SystemOptimizationHub - INFO - [START] STARTING TEST: Self-Healing Capabilities (self_healing)
2025-07-31 14:05:36,964 - SystemOptimizationHub - INFO - [START] STARTING TEST: Self-Healing Capabilities (self_healing)
[32m2025-07-31 14:05:36.965[0m | [1mINFO    [0m | [36msrc.utils.guardian_protocol[0m:[36m__init__[0m:[36m33[0m - [1mGuardian Protocol initialized - Quality assurance system active[0m
[32m2025-07-31 14:05:36.972[0m | [1mINFO    [0m | [36msrc.utils.phoenix_protocol[0m:[36m__init__[0m:[36m23[0m - [1mPhoenix Protocol initialized - Self-healing system active[0m
2025-07-31 14:05:36,973 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Self-Healing Capabilities - PASS
2025-07-31 14:05:36,979 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Self-Healing Capabilities - PASS
[32m2025-07-31 14:05:36.980[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Self-Healing Capabilities', 'category': 'self_healing', 'execution_time': 0.015633821487426758, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 31.2, 'cpu_usage': 15.6}}[0m
2025-07-31 14:05:36,986 - SystemOptimizationHub - INFO - [START] STARTING TEST: Stress Testing (stress_testing)
2025-07-31 14:05:36,988 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,992 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,994 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,997 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,999 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,002 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,005 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,007 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,009 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,011 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:37.219[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_0_1753988737[0m
[32m2025-07-31 14:05:37.471[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_1_1753988737[0m
[32m2025-07-31 14:05:37.720[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_2_1753988737[0m
[32m2025-07-31 14:05:38.207[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_3_1753988737[0m
[32m2025-07-31 14:05:38.448[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_4_1753988738[0m
[32m2025-07-31 14:05:38.707[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_5_1753988738[0m
[32m2025-07-31 14:05:38.957[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_6_1753988738[0m
[32m2025-07-31 14:05:39.207[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_7_1753988738[0m
[32m2025-07-31 14:05:39.466[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_8_1753988739[0m
[32m2025-07-31 14:05:39.785[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_9_1753988739[0m
[32m2025-07-31 14:05:40.025[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_10_1753988739[0m
[32m2025-07-31 14:05:40.297[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_11_1753988740[0m
[32m2025-07-31 14:05:40.557[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_12_1753988740[0m
[32m2025-07-31 14:05:40.825[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_13_1753988740[0m
[32m2025-07-31 14:05:41.073[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_14_1753988740[0m
2025-07-31 14:05:41,115 - urllib3.connectionpool - DEBUG - https://telemetry.crewai.com:4319 "POST /v1/traces HTTP/1.1" 200 2
[32m2025-07-31 14:05:41.318[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_15_1753988741[0m
[32m2025-07-31 14:05:41.594[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_16_1753988741[0m
[32m2025-07-31 14:05:41.842[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_17_1753988741[0m
[32m2025-07-31 14:05:42.098[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_18_1753988741[0m
[32m2025-07-31 14:05:42.364[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_19_1753988742[0m
[32m2025-07-31 14:05:42.619[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_20_1753988742[0m
[32m2025-07-31 14:05:42.872[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_21_1753988742[0m
[32m2025-07-31 14:05:43.157[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_22_1753988742[0m
[32m2025-07-31 14:05:43.407[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_23_1753988743[0m
[32m2025-07-31 14:05:43.667[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_24_1753988743[0m
[32m2025-07-31 14:05:43.933[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_25_1753988743[0m
[32m2025-07-31 14:05:44.219[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_26_1753988743[0m
[32m2025-07-31 14:05:44.485[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_27_1753988744[0m
[32m2025-07-31 14:05:44.754[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_28_1753988744[0m
[32m2025-07-31 14:05:45.097[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_29_1753988744[0m
[32m2025-07-31 14:05:45.338[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_30_1753988745[0m
[32m2025-07-31 14:05:45.595[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_31_1753988745[0m
[32m2025-07-31 14:05:45.877[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_32_1753988745[0m
[32m2025-07-31 14:05:46.151[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_33_1753988745[0m
[32m2025-07-31 14:05:46.406[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_34_1753988746[0m
[32m2025-07-31 14:05:46.673[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_35_1753988746[0m
[32m2025-07-31 14:05:46.925[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_36_1753988746[0m
[32m2025-07-31 14:05:47.191[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_37_1753988746[0m
[32m2025-07-31 14:05:47.511[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_38_1753988747[0m
[32m2025-07-31 14:05:47.789[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_39_1753988747[0m
[32m2025-07-31 14:05:48.049[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_40_1753988747[0m
[32m2025-07-31 14:05:48.313[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_41_1753988748[0m
[32m2025-07-31 14:05:48.565[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_42_1753988748[0m
[32m2025-07-31 14:05:48.822[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_43_1753988748[0m
[32m2025-07-31 14:05:49.067[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_44_1753988748[0m
[32m2025-07-31 14:05:49.334[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_45_1753988749[0m
[32m2025-07-31 14:05:49.595[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_46_1753988749[0m
[32m2025-07-31 14:05:49.846[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_47_1753988749[0m
[32m2025-07-31 14:05:50.099[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_48_1753988749[0m
[32m2025-07-31 14:05:50.342[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_49_1753988750[0m
[32m2025-07-31 14:05:50.380[0m | [1mINFO    [0m | [36msrc.utils.automated_debugger[0m:[36m__init__[0m:[36m36[0m - [1mAutomated Debugger initialized[0m
[32m2025-07-31 14:05:50.388[0m | [32m[1mSUCCESS [0m | [36msrc.utils.google_ai_wrapper[0m:[36m__init__[0m:[36m68[0m - [32m[1mGoogle Generative AI wrapper initialized successfully with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:50.391[0m | [1mINFO    [0m | [36msrc.utils.crewai_bypass[0m:[36mconfigure_direct_ai_environment[0m:[36m108[0m - [1mDirect AI environment configured - LiteLLM disabled[0m
2025-07-31 14:05:50,396 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Stress Testing - PASS
[32m2025-07-31 14:05:50.398[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Stress Testing', 'category': 'stress_testing', 'execution_time': 13.410770654678345, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.9, 'memory_delta': 0.10000000000000142, 'cpu_start': 43.8, 'cpu_end': 10.0, 'cpu_usage': 26.9}}[0m
[32m2025-07-31 14:05:50.399[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_suite_completed - {'total_tests': 14, 'total_time': 17.83361577987671, 'successful_tests': 12, 'failed_tests': 2, 'warning_tests': 0}[0m

================================================================================
üìä COMPREHENSIVE TEST REPORT
================================================================================
üéØ TOTAL TESTS: 14
‚úÖ PASSED: 12
‚ùå FAILED: 2
‚ö†Ô∏è WARNINGS: 0
üìà SUCCESS RATE: 85.7%
‚è±Ô∏è TOTAL EXECUTION TIME: 17.72s
üìä AVERAGE EXECUTION TIME: 1.27s
üöÄ SYSTEM STATUS: OPERATIONAL

üìà PERFORMANCE METRICS:
   avg_memory_start: 52.84
   max_memory_start: 53.00
   min_memory_start: 52.80
   avg_memory_end: 52.85
   max_memory_end: 53.00
   min_memory_end: 52.80
   avg_memory_delta: 0.01
   max_memory_delta: 0.20
   min_memory_delta: -0.20
   avg_cpu_start: 29.72
   max_cpu_start: 100.00
   min_cpu_start: 0.00
   avg_cpu_end: 24.45
   max_cpu_end: 100.00
   min_cpu_end: 0.00
   avg_cpu_usage: 27.09
   max_cpu_usage: 64.60
   min_cpu_usage: 4.15

üéØ DETAILED PERFORMANCE ANALYSIS:
   MEMORY: A - GOOD: Your system has adequate memory for most operations. Performance should be smooth.
      üîß Memory usage is healthy. Monitor during heavy workloads.
   CPU: A+ - EXCELLENT: CPU usage is very low. Your system has plenty of processing power available.
      üîß CPU performance is optimal. No action needed.
   DISK: A+ - EXCELLENT: Plenty of disk space available. No storage concerns.
      üîß Disk space is optimal. No action needed.
   LOAD_AVERAGE: A+ - EXCELLENT: System load is very low. Plenty of processing capacity available.
      üîß No recommendation available

   üéØ OVERALL: A+ (94/100)
      üí° Your system is performing exceptionally well! All resources are optimally utilized.
      üîß Your system is ready for intensive AI operations. No optimizations needed.

================================================================================
üí° USER GUIDANCE & EXPLANATIONS
================================================================================
üìä STATUS: OPERATIONAL
üìù EXPLANATION: ‚úÖ OPERATIONAL: Your system is working well with minor issues that don't affect core functionality.
üîç FAILED TESTS: üîß Workflow Phases: This component may need attention or configuration. | üîç Error Handling Test: This test INTENTIONALLY triggers errors to verify the system can handle them properly. A 'FAIL' here might actually indicate the system is working correctly by detecting errors.

üéØ RECOMMENDATIONS:
   1. üîß Review and fix the failed tests listed above
   2. üìà Monitor system performance closely
   3. üõ†Ô∏è Consider running specific component tests

üöÄ NEXT STEPS:
   1. üéØ Start using your system for real missions
   2. üìä Monitor performance in production
   3. üîÑ Run this test suite regularly
================================================================================

üìÑ Detailed report saved to: logs/system_optimization_report_20250731_140550.json
