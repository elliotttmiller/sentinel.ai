[32m2025-07-31 14:05:32.559[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36m_initialize_wandb[0m:[36m107[0m - [1mâœ… Weights & Biases initialized successfully[0m
2025-07-31 14:05:32,563 - SystemOptimizationHub - INFO - [INFO] Weave observability initialized for system optimization hub
ğŸ§ª Running comprehensive test suite...
ğŸš€ WEAVE-ENHANCED SYSTEM OPTIMIZATION HUB - Starting Comprehensive Test Suite
================================================================================
ğŸ” Full observability and monitoring enabled
================================================================================
2025-07-31 14:05:32,568 - SystemOptimizationHub - INFO - [START] STARTING TEST: System Initialization (system_initialization)
[32m2025-07-31 14:05:32.607[0m | [32m[1mSUCCESS [0m | [36msrc.utils.sentry_integration[0m:[36m_initialize_sentry[0m:[36m78[0m - [32m[1mSentry integration initialized successfully[0m
[32m2025-07-31 14:05:32.609[0m | [32m[1mSUCCESS [0m | [36msrc.utils.google_ai_wrapper[0m:[36m__init__[0m:[36m68[0m - [32m[1mGoogle Generative AI wrapper initialized successfully with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:32.610[0m | [1mINFO    [0m | [36msrc.core.cognitive_forge_engine[0m:[36m__init__[0m:[36m69[0m - [1mGoogle Generative AI initialized with model: gemini-1.5-pro[0m
2025-07-31 14:05:32,617 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): o4509683080822784.ingest.us.sentry.io:443
2025-07-31 14:05:32,618 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:32.618[0m | [1mINFO    [0m | [36msrc.utils.phoenix_protocol[0m:[36m__init__[0m:[36m23[0m - [1mPhoenix Protocol initialized - Self-healing system active[0m
2025-07-31 14:05:32,621 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:32,624 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:32.625[0m | [1mINFO    [0m | [36msrc.utils.guardian_protocol[0m:[36m__init__[0m:[36m33[0m - [1mGuardian Protocol initialized - Quality assurance system active[0m
[32m2025-07-31 14:05:32.625[0m | [1mINFO    [0m | [36msrc.utils.synapse_logging[0m:[36m__init__[0m:[36m33[0m - [1mSynapse Logging System initialized - Unified consciousness active[0m
2025-07-31 14:05:32,629 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:32,631 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:32.633[0m | [1mINFO    [0m | [36msrc.utils.self_learning_module[0m:[36m__init__[0m:[36m25[0m - [1mSelf-Learning Module initialized - Continuous improvement active[0m
[32m2025-07-31 14:05:32.633[0m | [1mINFO    [0m | [36msrc.core.cognitive_forge_engine[0m:[36m__init__[0m:[36m109[0m - [1mCognitive Forge Engine v5.0 initialized with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:32.634[0m | [1mINFO    [0m | [36msrc.core.cognitive_forge_engine[0m:[36m__init__[0m:[36m110[0m - [1mSentient Operating System: Phoenix Protocol, Guardian Protocol, and Synapse Logging active[0m
2025-07-31 14:05:32,644 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: System Initialization - PASS
[32m2025-07-31 14:05:32.646[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'System Initialization', 'category': 'system_initialization', 'execution_time': 0.07296872138977051, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 23.5, 'cpu_end': 34.6, 'cpu_usage': 29.05}}[0m
2025-07-31 14:05:32,652 - SystemOptimizationHub - INFO - [START] STARTING TEST: Environment Validation (environment_validation)
2025-07-31 14:05:32,657 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Environment Validation - PASS
[32m2025-07-31 14:05:32.658[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Environment Validation', 'category': 'environment_validation', 'execution_time': 0.0061190128326416016, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 50.0, 'cpu_end': 0.0, 'cpu_usage': 25.0}}[0m
2025-07-31 14:05:32,667 - SystemOptimizationHub - INFO - [START] STARTING TEST: Database Connectivity (database_integration)
[32m2025-07-31 14:05:32.908[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: test_db_1753988732[0m
2025-07-31 14:05:33,077 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Database Connectivity - PASS
[32m2025-07-31 14:05:33.078[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Database Connectivity', 'category': 'database_integration', 'execution_time': 0.41236066818237305, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 100.0, 'cpu_end': 14.9, 'cpu_usage': 57.45}}[0m
2025-07-31 14:05:33,080 - SystemOptimizationHub - INFO - [START] STARTING TEST: Agent Factory (agent_factory)
2025-07-31 14:05:33,085 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,090 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,092 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,095 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,097 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,100 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,103 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,105 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,108 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,111 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,113 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,120 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Agent Factory - PASS
[32m2025-07-31 14:05:33.121[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Agent Factory', 'category': 'agent_factory', 'execution_time': 0.035039663314819336, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 43.2, 'cpu_usage': 21.6}}[0m
2025-07-31 14:05:33,127 - SystemOptimizationHub - INFO - [START] STARTING TEST: Protocol Systems (protocol_systems)
2025-07-31 14:05:33,133 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Protocol Systems - PASS
[32m2025-07-31 14:05:33.134[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Protocol Systems', 'category': 'protocol_systems', 'execution_time': 0.005253314971923828, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 8.3, 'cpu_end': 0.0, 'cpu_usage': 4.15}}[0m
2025-07-31 14:05:33,142 - SystemOptimizationHub - INFO - [START] STARTING TEST: Workflow Phases (workflow_phases)
2025-07-31 14:05:33,145 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,155 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[36mâ•­â”€[0m[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[36m Crew Execution Started [0m[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[36mâ”€â•®[0m
[36mâ”‚[0m                                                                                                [36mâ”‚[0m
[36mâ”‚[0m  [1;36mCrew Execution Started[0m                                                                        [36mâ”‚[0m
[36mâ”‚[0m  [37mName: [0m[36mcrew[0m                                                                                    [36mâ”‚[0m
[36mâ”‚[0m  [37mID: [0m[36mda375292-0a07-47f9-8c49-b9134a51299e[0m                                                      [36mâ”‚[0m
[36mâ”‚[0m  [37mTool Args: [0m                                                                                   [36mâ”‚[0m
[36mâ”‚[0m                                                                                                [36mâ”‚[0m
[36mâ”‚[0m                                                                                                [36mâ”‚[0m
[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

2025-07-31 14:05:33,173 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
2025-07-31 14:05:33,178 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[?25l2025-07-31 14:05:33,182 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[1;36mğŸš€ Crew: [0m[1;36mcrew[0m
â””â”€â”€ [1;33mğŸ“‹ Task: a456c6ef-bd62-4801-be7c-41c8c28779c3[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
[?25h[35mâ•­â”€[0m[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[35m ğŸ¤– Agent Started [0m[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[35mâ”€â•®[0m
[35mâ”‚[0m                                                                                                [35mâ”‚[0m
[35mâ”‚[0m  [37mAgent: [0m[1;92mAdvanced Prompt Optimization Specialist[0m                                                [35mâ”‚[0m
[35mâ”‚[0m                                                                                                [35mâ”‚[0m
[35mâ”‚[0m  [37mTask: [0m[92mAnalyze and optimize the following user prompt: 'Create a simple Python web [0m            [35mâ”‚[0m
[35mâ”‚[0m  [92mapplication with FastAPI'.[0m                                                                    [35mâ”‚[0m
[35mâ”‚[0m  [92m                [0m                                                                              [35mâ”‚[0m
[35mâ”‚[0m  [92m                Your transformation process must include:[0m                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                1. **Ambiguity Resolution**: Clarify any vague terms[0m                          [35mâ”‚[0m
[35mâ”‚[0m  [92m                2. **Contextual Enrichment**: Add implicit technical constraints or context[0m   [35mâ”‚[0m
[35mâ”‚[0m  [92m                3. **Define Success Criteria**: Create a list of measurable outcomes[0m          [35mâ”‚[0m
[35mâ”‚[0m  [92m                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the[0m  [35mâ”‚[0m
[35mâ”‚[0m  [92mtask[0m                                                                                          [35mâ”‚[0m
[35mâ”‚[0m  [92m                5. **Structure the Output**: Return a single, raw JSON object containing the[0m  [35mâ”‚[0m
[35mâ”‚[0m  [92m'optimized_prompt', 'success_criteria', and 'recommended_agents'[0m                              [35mâ”‚[0m
[35mâ”‚[0m  [92m                [0m                                                                              [35mâ”‚[0m
[35mâ”‚[0m  [92m                Provide your response in the following JSON format:[0m                           [35mâ”‚[0m
[35mâ”‚[0m  [92m                {[0m                                                                             [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "optimized_prompt": "The enhanced, detailed version of the user's [0m        [35mâ”‚[0m
[35mâ”‚[0m  [92mrequest",[0m                                                                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "technical_context": {[0m                                                    [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "programming_languages": ["list", "of", "relevant", "languages"],[0m     [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "frameworks": ["list", "of", "relevant", "frameworks"],[0m               [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "tools_required": ["list", "of", "required", "tools"],[0m                [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "complexity_level": "low/medium/high",[0m                                [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "estimated_duration": "time estimate"[0m                                 [35mâ”‚[0m
[35mâ”‚[0m  [92m                    },[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "success_criteria": [[0m                                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "Specific, measurable criteria 1",[0m                                    [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "Specific, measurable criteria 2"[0m                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ],[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "recommended_agents": [[0m                                                   [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "agent_role_1",[0m                                                       [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "agent_role_2"[0m                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ],[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "risk_factors": [[0m                                                         [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "potential risk 1 with mitigation",[0m                                   [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "potential risk 2 with mitigation"[0m                                    [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ],[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "optimization_notes": [[0m                                                   [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "optimization suggestion 1",[0m                                          [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "optimization suggestion 2"[0m                                           [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ][0m                                                                         [35mâ”‚[0m
[35mâ”‚[0m  [92m                }[0m                                                                             [35mâ”‚[0m
[35mâ”‚[0m                                                                                                [35mâ”‚[0m
[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

[?25l2025-07-31 14:05:33,193 - LiteLLM - DEBUG -

2025-07-31 14:05:33,194 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
2025-07-31 14:05:33,195 - LiteLLM - DEBUG - [92mlitellm.completion(model='gemini-1.5-pro', messages=[{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'Create a simple Python web application with FastAPI\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], temperature=0.7, stop=['\nObserv
2025-07-31 14:05:33,195 - LiteLLM - DEBUG -

2025-07-31 14:05:33,196 - LiteLLM - DEBUG - Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>]
2025-07-31 14:05:33,197 - LiteLLM - DEBUG - self.optional_params: {}
2025-07-31 14:05:33,199 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-31 14:05:33,211 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,214 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-pro; provider = vertex_ai
2025-07-31 14:05:33,215 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-pro', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'vertex_ai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'Create a simple Python web application with FastAPI\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "p
2025-07-31 14:05:33,216 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:33,216 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}
2025-07-31 14:05:33,217 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:33,218 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,221 - LiteLLM - DEBUG - Checking cached credentials for project_id: None
2025-07-31 14:05:33,221 - LiteLLM - DEBUG - Credential cache key not found for project_id: None, loading new credentials
2025-07-31 14:05:33,224 - google.auth._default - DEBUG - Checking D:\AMD\secrets\nexus-ai-466614-377f29052243.json for explicit credentials as part of auth process...
2025-07-31 14:05:33,274 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
2025-07-31 14:05:33,288 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): oauth2.googleapis.com:443
[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:33,845 - urllib3.connectionpool - DEBUG - https://oauth2.googleapis.com:443 "POST /token HTTP/1.1" 200 None
2025-07-31 14:05:33,849 - LiteLLM - DEBUG - Validating credentials for project_id: None
2025-07-31 14:05:33,850 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,852 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:33,855 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent \
-H 'Content-Type: application/json' -H 'Authorization: Be****t8' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Analyze and optimize the following user prompt: \'Create a simple Python web application with FastAPI\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}], 'system_instruction': {'parts': [{'text': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}]}, 'generationConfig': {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}}'
[0m

[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:34,226 - httpcore.connection - DEBUG - connect_tcp.started host='us-central1-aiplatform.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-31 14:05:34,328 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C71A5A50>
2025-07-31 14:05:34,328 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C7C71ED130> server_hostname='us-central1-aiplatform.googleapis.com' timeout=600.0
2025-07-31 14:05:34,368 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C71A6490>
2025-07-31 14:05:34,371 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-31 14:05:34,371 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-31 14:05:34,371 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-31 14:05:34,372 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-31 14:05:34,373 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:34,519 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 31 Jul 2025 19:05:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-31 14:05:34,520 - httpx - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent "HTTP/1.1 404 Not Found"
2025-07-31 14:05:34,521 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-31 14:05:34,522 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-31 14:05:34,523 - httpcore.http11 - DEBUG - response_closed.started
2025-07-31 14:05:34,523 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-31 14:05:34,525 - LiteLLM - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-07-31 14:05:34,535 - LiteLLM - DEBUG - Logging Details LiteLLM-Failure Call: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>]
[2K[1;36mğŸš€ Crew: [0m[1;36mcrew[0m                    ...                                                [0m
â””â”€â”€ [1;33mğŸ“‹ Task: a456c6ef-bd62-4801-be7c-41c8c28779c3[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
    â””â”€â”€ [1;31mâŒ LLM Failed[0m
[?25h[31mâ•­â”€[0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31m LLM Error [0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31mâ”€â•®[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m  [1;31mâŒ LLM Call Failed[0m                                                                            [31mâ”‚[0m
[31mâ”‚[0m  [37mError: [0m[31mlitellm.NotFoundError: VertexAIException - {[0m                                           [31mâ”‚[0m
[31mâ”‚[0m  [31m  "error": {[0m                                                                                  [31mâ”‚[0m
[31mâ”‚[0m  [31m    "code": 404,[0m                                                                              [31mâ”‚[0m
[31mâ”‚[0m  [31m    "message": "Publisher Model [0m                                                              [31mâ”‚[0m
[31mâ”‚[0m  [31m`projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was[0m  [31mâ”‚[0m
[31mâ”‚[0m  [31mnot found or your project does not have access to it. Please ensure you are using a valid [0m    [31mâ”‚[0m
[31mâ”‚[0m  [31mmodel version. For more information, see: [0m                                                    [31mâ”‚[0m
[31mâ”‚[0m  [31mhttps://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",[0m                  [31mâ”‚[0m
[31mâ”‚[0m  [31m    "status": "NOT_FOUND"[0m                                                                     [31mâ”‚[0m
[31mâ”‚[0m  [31m  }[0m                                                                                           [31mâ”‚[0m
[31mâ”‚[0m  [31m}[0m                                                                                             [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

[?25l[1;36mğŸš€ Crew: [0m[1;36mcrew[0m
â””â”€â”€ [1;31mğŸ“‹ Task: a456c6ef-bd62-4801-be7c-41c8c28779c3[0m
    [37mAssigned to: [0m[31mAdvanced Prompt Optimization Specialist[0m
    [37mStatus: [0m[1;31mâŒ Failed[0m
    â””â”€â”€ [1;31mâŒ LLM Failed[0m
[?25h[31mâ•­â”€[0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31m Task Failure [0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31mâ”€â•®[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m  [1;31mTask Failed[0m                                                                                   [31mâ”‚[0m
[31mâ”‚[0m  [37mName: [0m[31ma456c6ef-bd62-4801-be7c-41c8c28779c3[0m                                                    [31mâ”‚[0m
[31mâ”‚[0m  [37mAgent: [0m[31mAdvanced Prompt Optimization Specialist[0m                                                [31mâ”‚[0m
[31mâ”‚[0m  [37mTool Args: [0m                                                                                   [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

[31mâ•­â”€[0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31m Crew Failure [0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31mâ”€â•®[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m  [1;31mCrew Execution Failed[0m                                                                         [31mâ”‚[0m
[31mâ”‚[0m  [37mName: [0m[31mcrew[0m                                                                                    [31mâ”‚[0m
[31mâ”‚[0m  [37mID: [0m[31mda375292-0a07-47f9-8c49-b9134a51299e[0m                                                      [31mâ”‚[0m
[31mâ”‚[0m  [37mTool Args: [0m                                                                                   [31mâ”‚[0m
[31mâ”‚[0m  [37mFinal Output: [0m                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m
[32m2025-07-31 14:05:34.558[0m | [31m[1mERROR   [0m | [36msrc.core.cognitive_forge_engine[0m:[36m_execute_prompt_alchemy[0m:[36m349[0m - [31m[1mPrompt optimization failed: litellm.NotFoundError: VertexAIException - {
  "error": {
    "code": 404,
    "message": "Publisher Model `projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
    "status": "NOT_FOUND"
  }
}
[0m

2025-07-31 14:05:34,576 - SystemOptimizationHub - INFO - [FAIL] TEST COMPLETED: Workflow Phases - FAIL
[32m2025-07-31 14:05:34.578[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_failure - {'test_name': 'Workflow Phases', 'category': 'workflow_phases', 'execution_time': 1.4334053993225098, 'error': "unsupported operand type(s) for +: 'int' and 'str'", 'performance_metrics': {'memory_start': 52.8, 'memory_end': 53.0, 'memory_delta': 0.20000000000000284, 'cpu_start': 43.8, 'cpu_end': 18.7, 'cpu_usage': 31.25}}[0m
2025-07-31 14:05:34,581 - SystemOptimizationHub - INFO - [START] STARTING TEST: Performance Optimization (performance_optimization)
ğŸš€ Testing System Performance & Optimization...
   ğŸ“Š This test evaluates your system's resource usage and performance capabilities
   ğŸ¯ Each metric is graded from A+ (Excellent) to F (Critical)

   ğŸ§  MEMORY USAGE ANALYSIS
      ğŸ“Š Usage: 52.9% (8.4GB / 15.9GB)
      ğŸ“Š Available: 7.5GB
      ğŸ¯ Grade: A
      ğŸ’¡ GOOD: Your system has adequate memory for most operations. Performance should be smooth.
      ğŸ”§ Recommendation: Memory usage is healthy. Monitor during heavy workloads.

   âš¡ CPU USAGE ANALYSIS
2025-07-31 14:05:34,641 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
2025-07-31 14:05:35,196 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): telemetry.crewai.com:4319
      ğŸ“Š Usage: 9.5%
      ğŸ“Š Cores: 16
      ğŸ“Š Frequency: 3700MHz
      ğŸ¯ Grade: A+
      ğŸ’¡ EXCELLENT: CPU usage is very low. Your system has plenty of processing power available.
      ğŸ”§ Recommendation: CPU performance is optimal. No action needed.

   ğŸ’¾ DISK USAGE ANALYSIS
      ğŸ“Š Usage: 56.9% (200.1GB free / 464.4GB total)
      ğŸ¯ Grade: A+
      ğŸ’¡ EXCELLENT: Plenty of disk space available. No storage concerns.
      ğŸ”§ Recommendation: Disk space is optimal. No action needed.

   ğŸ“ˆ SYSTEM LOAD ANALYSIS
      ğŸ“Š 1min: 0.00, 5min: 0.00, 15min: 0.00
      ğŸ¯ Grade: A+
      ğŸ’¡ EXCELLENT: System load is very low. Plenty of processing capacity available.

   ğŸ¯ OVERALL PERFORMANCE ASSESSMENT
      ğŸ¯ Overall Grade: A+ (94/100)
      ğŸ“Š Status: EXCELLENT
      ğŸ’¡ Your system is performing exceptionally well! All resources are optimally utilized.
      ğŸ”§ Your system is ready for intensive AI operations. No optimizations needed.

2025-07-31 14:05:35,951 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Performance Optimization - PASS
[32m2025-07-31 14:05:35.952[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Performance Optimization', 'category': 'performance_optimization', 'execution_time': 1.3671648502349854, 'performance_metrics': {'memory_start': 53.0, 'memory_end': 52.8, 'memory_delta': -0.20000000000000284, 'cpu_start': 0.0, 'cpu_end': 19.6, 'cpu_usage': 9.8}}[0m
2025-07-31 14:05:35,959 - SystemOptimizationHub - INFO - [START] STARTING TEST: Error Handling (error_handling)
ğŸ” Testing Error Handling Capabilities...
   ğŸ“ Note: These tests INTENTIONALLY trigger errors to verify proper handling
   âœ… A 'PASS' means the system correctly detected and handled the error
   âŒ A 'FAIL' means the system failed to handle the error properly

   ğŸ§ª Test 1: Empty Prompt Detection
2025-07-31 14:05:35,963 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:35,968 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[36mâ•­â”€[0m[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[36m Crew Execution Started [0m[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[36mâ”€â•®[0m
[36mâ”‚[0m                                                                                                [36mâ”‚[0m
[36mâ”‚[0m  [1;36mCrew Execution Started[0m                                                                        [36mâ”‚[0m
[36mâ”‚[0m  [37mName: [0m[36mcrew[0m                                                                                    [36mâ”‚[0m
[36mâ”‚[0m  [37mID: [0m[36me79e3957-18b0-4ca5-93c8-c612b1f5525b[0m                                                      [36mâ”‚[0m
[36mâ”‚[0m  [37mTool Args: [0m                                                                                   [36mâ”‚[0m
[36mâ”‚[0m                                                                                                [36mâ”‚[0m
[36mâ”‚[0m                                                                                                [36mâ”‚[0m
[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

2025-07-31 14:05:35,986 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[?25l2025-07-31 14:05:35,990 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[1;36mğŸš€ Crew: [0m[1;36mcrew[0m
â””â”€â”€ [1;33mğŸ“‹ Task: fc54f199-8112-4622-8c1f-cbea00fc02d6[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
[?25h[35mâ•­â”€[0m[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[35m ğŸ¤– Agent Started [0m[35mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[35mâ”€â•®[0m
[35mâ”‚[0m                                                                                                [35mâ”‚[0m
[35mâ”‚[0m  [37mAgent: [0m[1;92mAdvanced Prompt Optimization Specialist[0m                                                [35mâ”‚[0m
[35mâ”‚[0m                                                                                                [35mâ”‚[0m
[35mâ”‚[0m  [37mTask: [0m[92mAnalyze and optimize the following user prompt: ''.[0m                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                [0m                                                                              [35mâ”‚[0m
[35mâ”‚[0m  [92m                Your transformation process must include:[0m                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                1. **Ambiguity Resolution**: Clarify any vague terms[0m                          [35mâ”‚[0m
[35mâ”‚[0m  [92m                2. **Contextual Enrichment**: Add implicit technical constraints or context[0m   [35mâ”‚[0m
[35mâ”‚[0m  [92m                3. **Define Success Criteria**: Create a list of measurable outcomes[0m          [35mâ”‚[0m
[35mâ”‚[0m  [92m                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the[0m  [35mâ”‚[0m
[35mâ”‚[0m  [92mtask[0m                                                                                          [35mâ”‚[0m
[35mâ”‚[0m  [92m                5. **Structure the Output**: Return a single, raw JSON object containing the[0m  [35mâ”‚[0m
[35mâ”‚[0m  [92m'optimized_prompt', 'success_criteria', and 'recommended_agents'[0m                              [35mâ”‚[0m
[35mâ”‚[0m  [92m                [0m                                                                              [35mâ”‚[0m
[35mâ”‚[0m  [92m                Provide your response in the following JSON format:[0m                           [35mâ”‚[0m
[35mâ”‚[0m  [92m                {[0m                                                                             [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "optimized_prompt": "The enhanced, detailed version of the user's [0m        [35mâ”‚[0m
[35mâ”‚[0m  [92mrequest",[0m                                                                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "technical_context": {[0m                                                    [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "programming_languages": ["list", "of", "relevant", "languages"],[0m     [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "frameworks": ["list", "of", "relevant", "frameworks"],[0m               [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "tools_required": ["list", "of", "required", "tools"],[0m                [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "complexity_level": "low/medium/high",[0m                                [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "estimated_duration": "time estimate"[0m                                 [35mâ”‚[0m
[35mâ”‚[0m  [92m                    },[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "success_criteria": [[0m                                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "Specific, measurable criteria 1",[0m                                    [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "Specific, measurable criteria 2"[0m                                     [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ],[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "recommended_agents": [[0m                                                   [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "agent_role_1",[0m                                                       [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "agent_role_2"[0m                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ],[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "risk_factors": [[0m                                                         [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "potential risk 1 with mitigation",[0m                                   [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "potential risk 2 with mitigation"[0m                                    [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ],[0m                                                                        [35mâ”‚[0m
[35mâ”‚[0m  [92m                    "optimization_notes": [[0m                                                   [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "optimization suggestion 1",[0m                                          [35mâ”‚[0m
[35mâ”‚[0m  [92m                        "optimization suggestion 2"[0m                                           [35mâ”‚[0m
[35mâ”‚[0m  [92m                    ][0m                                                                         [35mâ”‚[0m
[35mâ”‚[0m  [92m                }[0m                                                                             [35mâ”‚[0m
[35mâ”‚[0m                                                                                                [35mâ”‚[0m
[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

[?25l2025-07-31 14:05:35,999 - LiteLLM - DEBUG -

2025-07-31 14:05:36,000 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
2025-07-31 14:05:36,000 - LiteLLM - DEBUG - [92mlitellm.completion(model='gemini-1.5-pro', messages=[{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], temperature=0.7, stop=['\nObservation:'], stream=False)[0m
2025-07-31 14:05:36,001 - LiteLLM - DEBUG -

2025-07-31 14:05:36,001 - LiteLLM - DEBUG - Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>], not adding again..
2025-07-31 14:05:36,002 - LiteLLM - DEBUG - Custom logger of type TokenCalcHandler, key: TokenCalcHandler already exists in [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>], not adding again..
2025-07-31 14:05:36,003 - LiteLLM - DEBUG - Initialized litellm callbacks, Async Success Callbacks: ['cache', <crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C7332250>]
2025-07-31 14:05:36,006 - LiteLLM - DEBUG - self.optional_params: {}
2025-07-31 14:05:36,007 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-07-31 14:05:36,009 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,010 - LiteLLM - INFO -
LiteLLM completion() model= gemini-1.5-pro; provider = vertex_ai
2025-07-31 14:05:36,011 - LiteLLM - DEBUG -
LiteLLM: Params passed to completion() {'model': 'gemini-1.5-pro', 'functions': None, 'function_call': None, 'temperature': 0.7, 'top_p': None, 'n': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'vertex_ai', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}, {'role': 'user', 'content': '\nCurrent Task: Analyze and optimize the following user prompt: \'\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n
2025-07-31 14:05:36,013 - LiteLLM - DEBUG -
LiteLLM: Non-Default params passed to completion() {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:36,015 - LiteLLM - DEBUG - Final returned optional params: {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}
2025-07-31 14:05:36,016 - LiteLLM - DEBUG - self.optional_params: {'temperature': 0.7, 'stream': False, 'stop': ['\nObservation:']}
2025-07-31 14:05:36,017 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,020 - LiteLLM - DEBUG - Checking cached credentials for project_id: None
2025-07-31 14:05:36,022 - LiteLLM - DEBUG - Cached credentials found for project_id: None.
2025-07-31 14:05:36,022 - LiteLLM - DEBUG - Using cached credentials
2025-07-31 14:05:36,025 - LiteLLM - DEBUG - Validating credentials for project_id: None
2025-07-31 14:05:36,026 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,027 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,028 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent \
-H 'Content-Type: application/json' -H 'Authorization: Be****t8' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Analyze and optimize the following user prompt: \'\'.\n                \n                Your transformation process must include:\n                1. **Ambiguity Resolution**: Clarify any vague terms\n                2. **Contextual Enrichment**: Add implicit technical constraints or context\n                3. **Define Success Criteria**: Create a list of measurable outcomes\n                4. **Recommend Agent Roles**: Suggest the primary agent roles needed for the task\n                5. **Structure the Output**: Return a single, raw JSON object containing the \'optimized_prompt\', \'success_criteria\', and \'recommended_agents\'\n                \n                Provide your response in the following JSON format:\n                {\n                    "optimized_prompt": "The enhanced, detailed version of the user\'s request",\n                    "technical_context": {\n                        "programming_languages": ["list", "of", "relevant", "languages"],\n                        "frameworks": ["list", "of", "relevant", "frameworks"],\n                        "tools_required": ["list", "of", "required", "tools"],\n                        "complexity_level": "low/medium/high",\n                        "estimated_duration": "time estimate"\n                    },\n                    "success_criteria": [\n                        "Specific, measurable criteria 1",\n                        "Specific, measurable criteria 2"\n                    ],\n                    "recommended_agents": [\n                        "agent_role_1",\n                        "agent_role_2"\n                    ],\n                    "risk_factors": [\n                        "potential risk 1 with mitigation",\n                        "potential risk 2 with mitigation"\n                    ],\n                    "optimization_notes": [\n                        "optimization suggestion 1",\n                        "optimization suggestion 2"\n                    ]\n                }\n\nThis is the expected criteria for your final answer: A structured JSON object with the optimized mission parameters.\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}], 'system_instruction': {'parts': [{'text': 'You are Advanced Prompt Optimization Specialist. You are the Advanced Prompt Optimization Specialist, a master of linguistic precision and AI communication. You have spent years studying how different AI models interpret and process information. You understand that the quality of the initial prompt determines the success of the entire mission. Your expertise lies in:\n- Deconstructing complex requests into clear, actionable components\n- Identifying missing context and adding necessary background information\n- Restructuring prompts for optimal AI comprehension\n- Adding specific success criteria and constraints\n- Ensuring technical accuracy and completeness\nYou are the first line of defense against mission failure due to poor communication.\nYour personal goal is: Transform raw user requests into perfectly optimized, structured prompts that are crystal clear for AI worker agents. Analyze, restructure, and enhance prompts to eliminate ambiguity, add necessary context, and ensure maximum comprehension by downstream agents. Your output must be a comprehensive JSON structure containing the optimized prompt, success criteria, constraints, and detailed instructions.\nTo give my best complete final answer to the task respond using the exact following format:\n\nThought: I now can give a great answer\nFinal Answer: Your final answer must be the great and the most complete as possible, it must be outcome described.\n\nI MUST use these formats, my job depends on it!'}]}, 'generationConfig': {'temperature': 0.7, 'stop_sequences': ['\nObservation:']}}'
[0m

2025-07-31 14:05:36,060 - urllib3.connectionpool - DEBUG - https://telemetry.crewai.com:4319 "POST /v1/traces HTTP/1.1" 200 2
[1;31m                                               ...                                                [0m2025-07-31 14:05:36,421 - httpcore.connection - DEBUG - connect_tcp.started host='us-central1-aiplatform.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-07-31 14:05:36,459 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C7618F10>
2025-07-31 14:05:36,460 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C7C76085F0> server_hostname='us-central1-aiplatform.googleapis.com' timeout=600.0
2025-07-31 14:05:36,493 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C7C7618ED0>
2025-07-31 14:05:36,494 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - send_request_body.complete
2025-07-31 14:05:36,495 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
[2K[1;31m                                               ...                                                [0m2025-07-31 14:05:36,657 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 31 Jul 2025 19:05:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-07-31 14:05:36,661 - httpx - INFO - HTTP Request: POST https://us-central1-aiplatform.googleapis.com/v1/projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro:generateContent "HTTP/1.1 404 Not Found"
2025-07-31 14:05:36,663 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-07-31 14:05:36,664 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-07-31 14:05:36,665 - httpcore.http11 - DEBUG - response_closed.started
2025-07-31 14:05:36,666 - httpcore.http11 - DEBUG - response_closed.complete
2025-07-31 14:05:36,667 - LiteLLM - DEBUG - Logging Details: logger_fn - None | callable(logger_fn) - False
2025-07-31 14:05:36,674 - LiteLLM - DEBUG - Logging Details LiteLLM-Failure Call: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x000001C7C712CF10>]
[2K[1;36mğŸš€ Crew: [0m[1;36mcrew[0m                    ...                                                [0m
â””â”€â”€ [1;33mğŸ“‹ Task: fc54f199-8112-4622-8c1f-cbea00fc02d6[0m
    [37mStatus: [0m[2;33mExecuting Task...[0m
    â””â”€â”€ [1;31mâŒ LLM Failed[0m
[?25h[31mâ•­â”€[0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31m LLM Error [0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31mâ”€â•®[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m  [1;31mâŒ LLM Call Failed[0m                                                                            [31mâ”‚[0m
[31mâ”‚[0m  [37mError: [0m[31mlitellm.NotFoundError: VertexAIException - {[0m                                           [31mâ”‚[0m
[31mâ”‚[0m  [31m  "error": {[0m                                                                                  [31mâ”‚[0m
[31mâ”‚[0m  [31m    "code": 404,[0m                                                                              [31mâ”‚[0m
[31mâ”‚[0m  [31m    "message": "Publisher Model [0m                                                              [31mâ”‚[0m
[31mâ”‚[0m  [31m`projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was[0m  [31mâ”‚[0m
[31mâ”‚[0m  [31mnot found or your project does not have access to it. Please ensure you are using a valid [0m    [31mâ”‚[0m
[31mâ”‚[0m  [31mmodel version. For more information, see: [0m                                                    [31mâ”‚[0m
[31mâ”‚[0m  [31mhttps://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",[0m                  [31mâ”‚[0m
[31mâ”‚[0m  [31m    "status": "NOT_FOUND"[0m                                                                     [31mâ”‚[0m
[31mâ”‚[0m  [31m  }[0m                                                                                           [31mâ”‚[0m
[31mâ”‚[0m  [31m}[0m                                                                                             [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

[?25l[1;36mğŸš€ Crew: [0m[1;36mcrew[0m
â””â”€â”€ [1;31mğŸ“‹ Task: fc54f199-8112-4622-8c1f-cbea00fc02d6[0m
    [37mAssigned to: [0m[31mAdvanced Prompt Optimization Specialist[0m
    [37mStatus: [0m[1;31mâŒ Failed[0m
    â””â”€â”€ [1;31mâŒ LLM Failed[0m
[?25h[31mâ•­â”€[0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31m Task Failure [0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31mâ”€â•®[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m  [1;31mTask Failed[0m                                                                                   [31mâ”‚[0m
[31mâ”‚[0m  [37mName: [0m[31mfc54f199-8112-4622-8c1f-cbea00fc02d6[0m                                                    [31mâ”‚[0m
[31mâ”‚[0m  [37mAgent: [0m[31mAdvanced Prompt Optimization Specialist[0m                                                [31mâ”‚[0m
[31mâ”‚[0m  [37mTool Args: [0m                                                                                   [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m

[31mâ•­â”€[0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31m Crew Failure [0m[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[0m[31mâ”€â•®[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m  [1;31mCrew Execution Failed[0m                                                                         [31mâ”‚[0m
[31mâ”‚[0m  [37mName: [0m[31mcrew[0m                                                                                    [31mâ”‚[0m
[31mâ”‚[0m  [37mID: [0m[31me79e3957-18b0-4ca5-93c8-c612b1f5525b[0m                                                      [31mâ”‚[0m
[31mâ”‚[0m  [37mTool Args: [0m                                                                                   [31mâ”‚[0m
[31mâ”‚[0m  [37mFinal Output: [0m                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ”‚[0m                                                                                                [31mâ”‚[0m
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯[0m
[32m2025-07-31 14:05:36.692[0m | [31m[1mERROR   [0m | [36msrc.core.cognitive_forge_engine[0m:[36m_execute_prompt_alchemy[0m:[36m349[0m - [31m[1mPrompt optimization failed: litellm.NotFoundError: VertexAIException - {
  "error": {
    "code": 404,
    "message": "Publisher Model `projects/nexus-ai-466614/locations/us-central1/publishers/google/models/gemini-1.5-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions",
    "status": "NOT_FOUND"
  }
}
[0m

      âœ… Expected error caught: NotFoundError
   ğŸ§ª Test 2: Database Error Handling
2025-07-31 14:05:36,781 - urllib3.connectionpool - DEBUG - https://o4509683080822784.ingest.us.sentry.io:443 "POST /api/4509764514938880/envelope/ HTTP/1.1" 200 0
      âœ… Database gracefully returned None for invalid mission ID
   ğŸ§ª Test 3: Agent Creation Error Handling

ğŸ“Š Error Handling Test Summary:
   âœ… empty_prompt_handling: PASSED - System correctly detected empty prompt
   âœ… database_error_handling: PASSED - Database returned None for invalid ID
   âŒ agent_creation_error_handling: FAILED - Agent creation should have failed

ğŸ’¡ Understanding Error Handling Tests:
   â€¢ These tests INTENTIONALLY trigger error conditions
   â€¢ A 'PASS' means the system correctly detected and handled the error
   â€¢ A 'FAIL' means the system failed to handle the error properly
   â€¢ The goal is to ensure the system is robust and doesn't crash

ğŸ“Š PERFORMANCE GRADING SCALE:
   ğŸ† A+ (95-100): EXCELLENT - Optimal performance, ready for intensive operations
   ğŸ¥‡ A  (90-94): GOOD - Strong performance with minor optimization opportunities
   ğŸ¥ˆ B  (80-89): ACCEPTABLE - Adequate performance, some areas for improvement
   ğŸ¥‰ C  (70-79): CONCERNING - Performance issues that should be addressed
   âš ï¸  D  (60-69): PROBLEMATIC - Significant performance problems
   ğŸš¨ F  (50-59): CRITICAL - Severe performance issues requiring immediate attention

ğŸ¯ WHY PERFORMANCE MATTERS FOR AI:
   â€¢ Memory: AI operations require significant RAM for processing large datasets
   â€¢ CPU: Complex AI calculations need processing power for timely results
   â€¢ Disk: AI models and data storage require adequate space
   â€¢ Load: System responsiveness affects AI operation efficiency
2025-07-31 14:05:36,841 - SystemOptimizationHub - INFO - [FAIL] TEST COMPLETED: Error Handling - FAIL
[32m2025-07-31 14:05:36.841[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_failure - {'test_name': 'Error Handling', 'category': 'error_handling', 'execution_time': 0.8813502788543701, 'error': 'Unknown error', 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.9, 'memory_delta': 0.10000000000000142, 'cpu_start': 0.0, 'cpu_end': 22.1, 'cpu_usage': 11.05}}[0m
2025-07-31 14:05:36,848 - SystemOptimizationHub - INFO - [START] STARTING TEST: Integration Tests (integration_tests)
2025-07-31 14:05:36,854 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Integration Tests - PASS
[32m2025-07-31 14:05:36.855[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Integration Tests', 'category': 'integration_tests', 'execution_time': 0.0066988468170166016, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.9, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 100.0, 'cpu_usage': 50.0}}[0m
2025-07-31 14:05:36,862 - SystemOptimizationHub - INFO - [START] STARTING TEST: Fix-AI Integration (fix_ai_integration)
2025-07-31 14:05:36,863 - SystemOptimizationHub - INFO - [START] STARTING TEST: Fix-AI Integration (fix_ai_integration)
[32m2025-07-31 14:05:36.870[0m | [32m[1mSUCCESS [0m | [36msrc.utils.google_ai_wrapper[0m:[36m__init__[0m:[36m68[0m - [32m[1mGoogle Generative AI wrapper initialized successfully with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:36.873[0m | [1mINFO    [0m | [36msrc.utils.crewai_bypass[0m:[36mconfigure_direct_ai_environment[0m:[36m108[0m - [1mDirect AI environment configured - LiteLLM disabled[0m
2025-07-31 14:05:36,875 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Fix-AI Integration - PASS
2025-07-31 14:05:36,882 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Fix-AI Integration - PASS
[32m2025-07-31 14:05:36.883[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Fix-AI Integration', 'category': 'fix_ai_integration', 'execution_time': 0.01949286460876465, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.9, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 18.8, 'cpu_usage': 9.4}}[0m
2025-07-31 14:05:36,889 - SystemOptimizationHub - INFO - [START] STARTING TEST: Automated Debugging System (automated_debugging)
2025-07-31 14:05:36,890 - SystemOptimizationHub - INFO - [START] STARTING TEST: Automated Debugging System (automated_debugging)
[32m2025-07-31 14:05:36.891[0m | [1mINFO    [0m | [36msrc.utils.automated_debugger[0m:[36m__init__[0m:[36m36[0m - [1mAutomated Debugger initialized[0m
[32m2025-07-31 14:05:36.892[0m | [1mINFO    [0m | [36msrc.utils.crewai_bypass[0m:[36mconfigure_direct_ai_environment[0m:[36m108[0m - [1mDirect AI environment configured - LiteLLM disabled[0m
2025-07-31 14:05:36,893 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Automated Debugging System - PASS
2025-07-31 14:05:36,898 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Automated Debugging System - PASS
[32m2025-07-31 14:05:36.899[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Automated Debugging System', 'category': 'automated_debugging', 'execution_time': 0.009461641311645508, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.9, 'memory_delta': 0.0, 'cpu_start': 46.7, 'cpu_end': 0.0, 'cpu_usage': 23.35}}[0m
2025-07-31 14:05:36,906 - SystemOptimizationHub - INFO - [START] STARTING TEST: Sentry Integration (sentry_integration)
2025-07-31 14:05:36,907 - SystemOptimizationHub - INFO - [START] STARTING TEST: Sentry Integration (sentry_integration)
[32m2025-07-31 14:05:36.948[0m | [32m[1mSUCCESS [0m | [36msrc.utils.sentry_integration[0m:[36m_initialize_sentry[0m:[36m78[0m - [32m[1mSentry integration initialized successfully[0m
2025-07-31 14:05:36,949 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Sentry Integration - PASS
2025-07-31 14:05:36,955 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Sentry Integration - PASS
[32m2025-07-31 14:05:36.956[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Sentry Integration', 'category': 'sentry_integration', 'execution_time': 0.04905509948730469, 'performance_metrics': {'memory_start': 52.9, 'memory_end': 52.8, 'memory_delta': -0.10000000000000142, 'cpu_start': 100.0, 'cpu_end': 29.2, 'cpu_usage': 64.6}}[0m
2025-07-31 14:05:36,963 - SystemOptimizationHub - INFO - [START] STARTING TEST: Self-Healing Capabilities (self_healing)
2025-07-31 14:05:36,964 - SystemOptimizationHub - INFO - [START] STARTING TEST: Self-Healing Capabilities (self_healing)
[32m2025-07-31 14:05:36.965[0m | [1mINFO    [0m | [36msrc.utils.guardian_protocol[0m:[36m__init__[0m:[36m33[0m - [1mGuardian Protocol initialized - Quality assurance system active[0m
[32m2025-07-31 14:05:36.972[0m | [1mINFO    [0m | [36msrc.utils.phoenix_protocol[0m:[36m__init__[0m:[36m23[0m - [1mPhoenix Protocol initialized - Self-healing system active[0m
2025-07-31 14:05:36,973 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Self-Healing Capabilities - PASS
2025-07-31 14:05:36,979 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Self-Healing Capabilities - PASS
[32m2025-07-31 14:05:36.980[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Self-Healing Capabilities', 'category': 'self_healing', 'execution_time': 0.015633821487426758, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.8, 'memory_delta': 0.0, 'cpu_start': 0.0, 'cpu_end': 31.2, 'cpu_usage': 15.6}}[0m
2025-07-31 14:05:36,986 - SystemOptimizationHub - INFO - [START] STARTING TEST: Stress Testing (stress_testing)
2025-07-31 14:05:36,988 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,992 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,994 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,997 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:36,999 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,002 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,005 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,007 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,009 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
2025-07-31 14:05:37,011 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro', 'combined_model_name': 'vertex_ai/gemini-1.5-pro', 'stripped_model_name': 'gemini-1.5-pro', 'combined_stripped_model_name': 'vertex_ai/gemini-1.5-pro', 'custom_llm_provider': 'vertex_ai'}
[32m2025-07-31 14:05:37.219[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_0_1753988737[0m
[32m2025-07-31 14:05:37.471[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_1_1753988737[0m
[32m2025-07-31 14:05:37.720[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_2_1753988737[0m
[32m2025-07-31 14:05:38.207[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_3_1753988737[0m
[32m2025-07-31 14:05:38.448[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_4_1753988738[0m
[32m2025-07-31 14:05:38.707[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_5_1753988738[0m
[32m2025-07-31 14:05:38.957[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_6_1753988738[0m
[32m2025-07-31 14:05:39.207[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_7_1753988738[0m
[32m2025-07-31 14:05:39.466[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_8_1753988739[0m
[32m2025-07-31 14:05:39.785[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_9_1753988739[0m
[32m2025-07-31 14:05:40.025[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_10_1753988739[0m
[32m2025-07-31 14:05:40.297[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_11_1753988740[0m
[32m2025-07-31 14:05:40.557[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_12_1753988740[0m
[32m2025-07-31 14:05:40.825[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_13_1753988740[0m
[32m2025-07-31 14:05:41.073[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_14_1753988740[0m
2025-07-31 14:05:41,115 - urllib3.connectionpool - DEBUG - https://telemetry.crewai.com:4319 "POST /v1/traces HTTP/1.1" 200 2
[32m2025-07-31 14:05:41.318[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_15_1753988741[0m
[32m2025-07-31 14:05:41.594[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_16_1753988741[0m
[32m2025-07-31 14:05:41.842[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_17_1753988741[0m
[32m2025-07-31 14:05:42.098[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_18_1753988741[0m
[32m2025-07-31 14:05:42.364[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_19_1753988742[0m
[32m2025-07-31 14:05:42.619[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_20_1753988742[0m
[32m2025-07-31 14:05:42.872[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_21_1753988742[0m
[32m2025-07-31 14:05:43.157[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_22_1753988742[0m
[32m2025-07-31 14:05:43.407[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_23_1753988743[0m
[32m2025-07-31 14:05:43.667[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_24_1753988743[0m
[32m2025-07-31 14:05:43.933[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_25_1753988743[0m
[32m2025-07-31 14:05:44.219[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_26_1753988743[0m
[32m2025-07-31 14:05:44.485[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_27_1753988744[0m
[32m2025-07-31 14:05:44.754[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_28_1753988744[0m
[32m2025-07-31 14:05:45.097[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_29_1753988744[0m
[32m2025-07-31 14:05:45.338[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_30_1753988745[0m
[32m2025-07-31 14:05:45.595[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_31_1753988745[0m
[32m2025-07-31 14:05:45.877[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_32_1753988745[0m
[32m2025-07-31 14:05:46.151[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_33_1753988745[0m
[32m2025-07-31 14:05:46.406[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_34_1753988746[0m
[32m2025-07-31 14:05:46.673[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_35_1753988746[0m
[32m2025-07-31 14:05:46.925[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_36_1753988746[0m
[32m2025-07-31 14:05:47.191[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_37_1753988746[0m
[32m2025-07-31 14:05:47.511[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_38_1753988747[0m
[32m2025-07-31 14:05:47.789[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_39_1753988747[0m
[32m2025-07-31 14:05:48.049[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_40_1753988747[0m
[32m2025-07-31 14:05:48.313[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_41_1753988748[0m
[32m2025-07-31 14:05:48.565[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_42_1753988748[0m
[32m2025-07-31 14:05:48.822[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_43_1753988748[0m
[32m2025-07-31 14:05:49.067[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_44_1753988748[0m
[32m2025-07-31 14:05:49.334[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_45_1753988749[0m
[32m2025-07-31 14:05:49.595[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_46_1753988749[0m
[32m2025-07-31 14:05:49.846[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_47_1753988749[0m
[32m2025-07-31 14:05:50.099[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_48_1753988749[0m
[32m2025-07-31 14:05:50.342[0m | [1mINFO    [0m | [36msrc.models.advanced_database[0m:[36mcreate_mission[0m:[36m147[0m - [1mCreated mission: stress_test_49_1753988750[0m
[32m2025-07-31 14:05:50.380[0m | [1mINFO    [0m | [36msrc.utils.automated_debugger[0m:[36m__init__[0m:[36m36[0m - [1mAutomated Debugger initialized[0m
[32m2025-07-31 14:05:50.388[0m | [32m[1mSUCCESS [0m | [36msrc.utils.google_ai_wrapper[0m:[36m__init__[0m:[36m68[0m - [32m[1mGoogle Generative AI wrapper initialized successfully with model: gemini-1.5-pro[0m
[32m2025-07-31 14:05:50.391[0m | [1mINFO    [0m | [36msrc.utils.crewai_bypass[0m:[36mconfigure_direct_ai_environment[0m:[36m108[0m - [1mDirect AI environment configured - LiteLLM disabled[0m
2025-07-31 14:05:50,396 - SystemOptimizationHub - INFO - [PASS] TEST COMPLETED: Stress Testing - PASS
[32m2025-07-31 14:05:50.398[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_success - {'test_name': 'Stress Testing', 'category': 'stress_testing', 'execution_time': 13.410770654678345, 'performance_metrics': {'memory_start': 52.8, 'memory_end': 52.9, 'memory_delta': 0.10000000000000142, 'cpu_start': 43.8, 'cpu_end': 10.0, 'cpu_usage': 26.9}}[0m
[32m2025-07-31 14:05:50.399[0m | [1mINFO    [0m | [36msrc.utils.weave_observability[0m:[36mlog_system_event[0m:[36m255[0m - [1mSystem event: test_suite_completed - {'total_tests': 14, 'total_time': 17.83361577987671, 'successful_tests': 12, 'failed_tests': 2, 'warning_tests': 0}[0m

================================================================================
ğŸ“Š COMPREHENSIVE TEST REPORT
================================================================================
ğŸ¯ TOTAL TESTS: 14
âœ… PASSED: 12
âŒ FAILED: 2
âš ï¸ WARNINGS: 0
ğŸ“ˆ SUCCESS RATE: 85.7%
â±ï¸ TOTAL EXECUTION TIME: 17.72s
ğŸ“Š AVERAGE EXECUTION TIME: 1.27s
ğŸš€ SYSTEM STATUS: OPERATIONAL

ğŸ“ˆ PERFORMANCE METRICS:
   avg_memory_start: 52.84
   max_memory_start: 53.00
   min_memory_start: 52.80
   avg_memory_end: 52.85
   max_memory_end: 53.00
   min_memory_end: 52.80
   avg_memory_delta: 0.01
   max_memory_delta: 0.20
   min_memory_delta: -0.20
   avg_cpu_start: 29.72
   max_cpu_start: 100.00
   min_cpu_start: 0.00
   avg_cpu_end: 24.45
   max_cpu_end: 100.00
   min_cpu_end: 0.00
   avg_cpu_usage: 27.09
   max_cpu_usage: 64.60
   min_cpu_usage: 4.15

ğŸ¯ DETAILED PERFORMANCE ANALYSIS:
   MEMORY: A - GOOD: Your system has adequate memory for most operations. Performance should be smooth.
      ğŸ”§ Memory usage is healthy. Monitor during heavy workloads.
   CPU: A+ - EXCELLENT: CPU usage is very low. Your system has plenty of processing power available.
      ğŸ”§ CPU performance is optimal. No action needed.
   DISK: A+ - EXCELLENT: Plenty of disk space available. No storage concerns.
      ğŸ”§ Disk space is optimal. No action needed.
   LOAD_AVERAGE: A+ - EXCELLENT: System load is very low. Plenty of processing capacity available.
      ğŸ”§ No recommendation available

   ğŸ¯ OVERALL: A+ (94/100)
      ğŸ’¡ Your system is performing exceptionally well! All resources are optimally utilized.
      ğŸ”§ Your system is ready for intensive AI operations. No optimizations needed.

================================================================================
ğŸ’¡ USER GUIDANCE & EXPLANATIONS
================================================================================
ğŸ“Š STATUS: OPERATIONAL
ğŸ“ EXPLANATION: âœ… OPERATIONAL: Your system is working well with minor issues that don't affect core functionality.
ğŸ” FAILED TESTS: ğŸ”§ Workflow Phases: This component may need attention or configuration. | ğŸ” Error Handling Test: This test INTENTIONALLY triggers errors to verify the system can handle them properly. A 'FAIL' here might actually indicate the system is working correctly by detecting errors.

ğŸ¯ RECOMMENDATIONS:
   1. ğŸ”§ Review and fix the failed tests listed above
   2. ğŸ“ˆ Monitor system performance closely
   3. ğŸ› ï¸ Consider running specific component tests

ğŸš€ NEXT STEPS:
   1. ğŸ¯ Start using your system for real missions
   2. ğŸ“Š Monitor performance in production
   3. ğŸ”„ Run this test suite regularly
================================================================================

ğŸ“„ Detailed report saved to: logs/system_optimization_report_20250731_140550.json
